# Hand Sign Language Detection

This project leverages computer vision and machine learning techniques to recognize hand gestures and translate them into meaningful sign language. The model is built using **MediaPipe** for hand landmark detection, **OpenCV** for image processing, and **Random Forest** (or any model you used) for classification.
The model is a Random Forest Classifier (or the model you used), trained on hand gesture images. The model achieves 100% accuracy on the test set, making it suitable for real-time applications.
## Features

- Real-time hand gesture recognition using a webcam.
- Recognizes a variety of hand gestures corresponding to sign language.
- High accuracy model for sign language classification (100% accuracy).
- Easy to use and deploy for sign language translation applications.


## Requirements

To run this project, you'll need to install the following dependencies:

- Python 3.x
- MediaPipe
- OpenCV
- scikit-learn (for the machine learning model)
- TensorFlow (if you used it for training)

You can install the necessary libraries using:

```bash
pip install -r requirements.txt

